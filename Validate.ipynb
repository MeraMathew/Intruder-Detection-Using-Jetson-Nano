{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f654e4-78f6-425c-a667-7ad37ed9f6bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.96 ðŸš€ Python-3.10.12 torch-2.1.0 CUDA:0 (Orin, 7620MiB)\n",
      "Model summary (fused): 72 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /intruder_dataset/labels/val.cache... 13582 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13582/13582 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /intruder_dataset/images/val/000000214087.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [07:39<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      13582      60715      0.593      0.376      0.502      0.361\n",
      "                person      12831      52767      0.778      0.669      0.763      0.576\n",
      "              backpack       1155       1797      0.542      0.139      0.338      0.201\n",
      "               handbag       1383       2501      0.529     0.0992      0.307       0.18\n",
      "              suitcase        507       1380      0.486      0.431      0.473      0.315\n",
      "            cell phone        974       1269      0.496      0.298      0.397      0.298\n",
      "                laptop        694       1001      0.727      0.622      0.732      0.597\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Saving runs/detect/val/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('runs/detect/intruder_yolov8n2/weights/best.pt')\n",
    "\n",
    "metrics = model.val(\n",
    "    save_json=True,\n",
    "    conf=0.25,\n",
    "    iou=0.5,\n",
    "    split=\"val\",\n",
    "    workers=0  #avoids shared memory errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242d5c18-47e7-44d0-8197-a76d7fb2f18b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.96 ðŸš€ Python-3.10.12 torch-2.1.0 CUDA:0 (Orin, 7620MiB)\n",
      "Model summary (fused): 72 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /intruder_dataset/labels/val.cache... 13582 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13582/13582 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /intruder_dataset/images/val/000000214087.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [07:31<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      13582      60715      0.519      0.402      0.417      0.281\n",
      "                person      12831      52767      0.683      0.702      0.742      0.514\n",
      "              backpack       1155       1797      0.453      0.195       0.21      0.105\n",
      "               handbag       1383       2501      0.411       0.15      0.161     0.0794\n",
      "              suitcase        507       1380      0.461      0.406        0.4      0.248\n",
      "            cell phone        974       1269      0.437       0.32      0.305      0.206\n",
      "                laptop        694       1001      0.669       0.64      0.686      0.536\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val_clean\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/intruder_yolov8n6/weights/last.pt\") \n",
    "metrics = model.val(\n",
    "    workers=0,               # Prevents shared memory crash\n",
    "    save=True,               # Saves prediction images\n",
    "    name=\"val_clean\"         # New clean folder for output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82633689-85c5-44f9-896a-ab3b04bbf761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
