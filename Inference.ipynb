{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9f40f0-a592-4867-835c-89134ebd6bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â›” Interrupted by user.\n",
      "âœ… Camera released.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Load trained model\n",
    "model = YOLO(\"runs/detect/intruder_yolov8n2/weights/best.pt\")\n",
    "\n",
    "# Detection parameters\n",
    "target_class = \"person\"  # Change back to \"backpack\" for your project\n",
    "min_confidence = 0.5\n",
    "alert_hold_time = 5  # seconds of persistent detection required\n",
    "fps = 10\n",
    "video_frame_buffer = deque(maxlen=fps * alert_hold_time)\n",
    "class_buffer = deque(maxlen=fps * alert_hold_time)\n",
    "\n",
    "# Get save path (same directory as notebook)\n",
    "save_dir = os.getcwd()\n",
    "\n",
    "# Open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_idx = 0\n",
    "detection_start_time = None\n",
    "alert_triggered = False\n",
    "\n",
    "# Get video frame size\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_idx += 1\n",
    "        current_frame_classes = []\n",
    "\n",
    "        # Inference\n",
    "        results = model(frame, verbose=False)[0]\n",
    "\n",
    "        for box in results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            name = model.names[cls_id]\n",
    "\n",
    "            if conf > 0.25:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                label = f\"{name} {conf:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "            if name == target_class and conf > min_confidence:\n",
    "                current_frame_classes.append(name)\n",
    "\n",
    "        # Logging detection\n",
    "        if target_class in current_frame_classes:\n",
    "            print(f\"ðŸ“Œ Detected: {target_class} at frame {frame_idx}\")\n",
    "            if detection_start_time is None:\n",
    "                detection_start_time = time.time()\n",
    "        else:\n",
    "            detection_start_time = None\n",
    "            alert_triggered = False\n",
    "\n",
    "        # Buffer management\n",
    "        class_buffer.append(current_frame_classes)\n",
    "        video_frame_buffer.append(frame.copy())\n",
    "\n",
    "        # Check for persistent detection\n",
    "        if detection_start_time:\n",
    "            elapsed = time.time() - detection_start_time\n",
    "            if elapsed >= alert_hold_time and not alert_triggered:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                img_path = os.path.join(save_dir, f\"alert_{target_class}_{timestamp}.jpg\")\n",
    "                video_path = os.path.join(save_dir, f\"alert_{target_class}_{timestamp}.mp4\")\n",
    "\n",
    "                # Save alert image\n",
    "                cv2.imwrite(img_path, frame)\n",
    "                print(f\"âœ… Alert image saved: {img_path}\")\n",
    "\n",
    "                # Save alert video\n",
    "                out = cv2.VideoWriter(video_path,\n",
    "                                      cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                                      fps,\n",
    "                                      (frame_width, frame_height))\n",
    "                for f in video_frame_buffer:\n",
    "                    out.write(f)\n",
    "                out.release()\n",
    "                print(f\"ðŸŽ¥ Alert video saved: {video_path}\")\n",
    "\n",
    "                alert_triggered = True\n",
    "                detection_start_time = None\n",
    "                video_frame_buffer.clear()\n",
    "\n",
    "        # Display in notebook\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame_rgb)\n",
    "        clear_output(wait=True)\n",
    "        display(img)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"â›” Interrupted by user.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"âœ… Camera released.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
